Intro 1: static search tree
-------

Take a binary search tree, cut it in half, then squash 
each subtree and arrange in order. 

Cost:
MT cost:

When do we stop this splitting ? We stop when the height of the
tree is at most lg B, that's 

Intro 2: MT analysis of merge sort
----------------------------------

Let's begin with binary merge sort.

Recursive MT cost formula for binary merge sort:

MT(N) = 2 * MT(N/2) + O(N/b)

Base case:

MT(M)  = M/b for some constant

so, for right part of recursion:

N/b

1/2 N/b + 1/2 N/b

1/4N/b + 1/4 N/b ...


lg2N/b - number of levels

for the other part


Conclusion:

MT(binary merge-sort) = N/b lg2 (N/M) 

Intro 3: Cache-aware merge sort Mt analysis
-------------------------------------------

what are the most pieces that I would be able to split this into?

up to the level you can merge in cache

for each of the lists I must be able to store the block in cache

How many blocks can I store in cache? M/B

MT = M/B * O(M/B) + O(N/B)

We divide into M/B equal size subarrays then recurse, then sort

The merge sort cost doesn't increase - (individual)

What changes is the number of levels.

Height of this tree is lgM/B(N/M) + 1

log m/b(n/m) =  lg M/b (N/b) 

mt(N) = N/b lg m/b N/b

- the sorting bound - optimal number of memory transfer for sorting 
N items cache aware

Finally: cache-oblivious merge sort
-----------------------------------

So we're going to do essentially sqrt(N) way merge sort

But we merge them fancily - divide and conquer merge, so that
no matter how many lists we merge, we can do it cache efficiently

Cache oblivius sorting
---------------------

To do cache oblivious sorting, you need an assumption about cache
size.

The knowledge you need to know is: assume the cache is tall, 
it has at least B blocks of size B, i.e. B ^ (1+epsilon)

The cache is at least as tall as it is wide it's a pretty reasonable
assumption.

If M is at least B^2 then we can do N ^ 1/3 merge sort

Here's why:

K-funnel merge, K-funnel

it merges K sorted lists and assuming that the lists are relatively 
long, each list must be at least K^2.

The total size of these lists must be thus K^3 at least.

Why we need relatively long lists?

Essentially funnel sort is qubrid(N)-way merge sort.

K = N ^ 1/3

So we essentially (1) divide array into N ^ 1/3 subarrays - segments,
(2) recursively sort them, (3) and then merge using the K-funnel.

If N = K^3 wasn't the requirement, then one would could just say:
hey, I have N lists, each of size 1. That would of course not work.

Algorithm cost bounds, for MT cost model:

- the cost of the sort, plus the cost of the merge

MT(N) = N^1/3 MT(N^2/3) + O(N/B log M/B N/B + N^1/3) 


How big is N^1/3 ? What's bigger, the first part or the second part
of the recurrence, given the cache is B^2 at least?
